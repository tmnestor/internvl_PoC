# ==========================================================================
# InternVL Configuration Template - Australian Tax Office Version
# ==========================================================================
# This file is a template for the .env configuration file.
# Copy this file to .env in the project root and update the paths.
# Paths can be relative to the project root for KFP compatibility.

# --------------------------------------------------------------------------
# ENVIRONMENT CONFIGURATION
# --------------------------------------------------------------------------
# Optional: Set the environment (discovery, staging, production)
# If not set, environment will be detected as "unknown"
INTERNVL_ENV=discovery

# --------------------------------------------------------------------------
# PATH CONFIGURATION
# --------------------------------------------------------------------------
# REQUIRED: These paths can be relative to INTERNVL_PROJECT_ROOT for KFP compatibility

# Base paths (all relative to project root)
INTERNVL_PROJECT_ROOT=.
INTERNVL_DATA_PATH=data
INTERNVL_OUTPUT_PATH=output
INTERNVL_SOURCE_PATH=internvl
INTERNVL_PROMPTS_PATH=prompts.yaml

# Derived paths
INTERNVL_SYNTHETIC_DATA_PATH=${INTERNVL_DATA_PATH}/synthetic
INTERNVL_SROIE_DATA_PATH=${INTERNVL_DATA_PATH}/sroie
INTERNVL_IMAGE_FOLDER_PATH=${INTERNVL_SYNTHETIC_DATA_PATH}/images

# Base name for output files
INTERNVL_OUTPUT_FILE_NAME=ato_extracted_info_

# Path/name of the InternVL model to use
# NOTE: This can be either a HuggingFace model ID or an absolute path
# For KFP, this will need to be configured in the pipeline dynamically
# INTERNVL_MODEL_PATH=/Users/tod/PretrainedLLM/InternVL2_5-1B  # Local development path
# INTERNVL_MODEL_PATH=/home/jovyan/nfs_share/models/InternVL2_5-1B  # Remote shared path
# INTERNVL_MODEL_PATH=/Users/tod/PretrainedLLM/InternVL3-1B
# INTERNVL_MODEL_PATH=/Users/tod/PretrainedLLM/InternVL3-8B

# Use clean extracted model directory (no more storage mapping!)
INTERNVL_MODEL_PATH=/home/jovyan/nfs_share/models/InternVL3-8B

# Force offline mode to prevent unwanted downloads
HF_DATASETS_OFFLINE=1
TRANSFORMERS_OFFLINE=1

# --------------------------------------------------------------------------
# IMAGE PREPROCESSING PARAMETERS
# --------------------------------------------------------------------------
# Smaller values for faster development iterations
INTERNVL_IMAGE_SIZE=448
INTERNVL_MAX_TILES=8

# --------------------------------------------------------------------------
# INFERENCE CONFIGURATION
# --------------------------------------------------------------------------
# Fewer workers for development machines
INTERNVL_MAX_WORKERS=6
INTERNVL_MAX_TOKENS=1024
INTERNVL_DO_SAMPLE=False

# Suppress transformers library warnings (ERROR, WARNING, INFO, DEBUG)
INTERNVL_TRANSFORMERS_LOG_LEVEL=ERROR

# --------------------------------------------------------------------------
# OUTPUT CONFIGURATION
# --------------------------------------------------------------------------
# Save all predictions during development
INTERNVL_SAVE_PREDICTIONS=true

# --------------------------------------------------------------------------
# CONFIDENCE SCORING CONFIGURATION
# --------------------------------------------------------------------------
# Enable confidence scoring and selective reprocessing
INTERNVL_ENABLE_CONFIDENCE_SCORING=true

# Confidence threshold for reprocessing (0.0-1.0)
INTERNVL_CONFIDENCE_THRESHOLD=0.7

# Fallback prompt for low-confidence predictions
INTERNVL_FALLBACK_PROMPT_NAME=ultra_strict_json_prompt

# --------------------------------------------------------------------------
# PROMPT TEMPLATE
# --------------------------------------------------------------------------
# The path to the YAML file containing prompts (already set above)
# INTERNVL_PROMPTS_PATH is already defined to prompts.yaml

# The name of the prompt to use from the YAML file
# INTERNVL_PROMPT_NAME=default_receipt_prompt

# Use original Huaifeng prompts for compatibility
# INTERNVL_PROMPT_NAME=huaifeng_receipt_json_prompt

# Use enhanced JSON prompt with comprehensive error prevention  
INTERNVL_PROMPT_NAME=enhanced_json_prompt

# Use for conference document analysis
# INTERNVL_PROMPT_NAME=conference_relevance_prompt